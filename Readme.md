CohortIQ
Project Overview
CohortIQ is a churn prediction and user segmentation dashboard for Software-as-a-Service (SaaS) platforms. It enables data teams and product managers to identify users at risk of churning (leaving the service) and understand user behavior patterns. The dashboard integrates a machine learning model that predicts churn risk for each user, and provides interactive visualizations for exploring cohorts, retention, and user segments. This project was built as part of a student portfolio to showcase skills in data science, machine learning, and full-stack development (from database to interactive web app). The result is a self-contained tool that demonstrates how predictive analytics and cohort analysis can drive actionable insights to improve user retention.
Key Features
üîÆ Churn Prediction (Neural Network): Uses a TensorFlow-based neural network model to predict the probability of each user churning. The model analyzes user activity data (e.g., session counts, durations, recency) to determine who is likely to churn, enabling proactive retention efforts.
üí° Explainable AI (LIME): Incorporates Local Interpretable Model-Agnostic Explanations (LIME) to explain the churn predictions. For any given user, LIME can highlight which features (e.g. number of sessions, time since last visit) pushed the model toward predicting churn or not churn, making the model‚Äôs decisions transparent.
üéØ User Segmentation (GMM Clustering): Employs Gaussian Mixture Model clustering on user behavior metrics to segment users into distinct groups. This unsupervised learning groups similar users together (e.g., ‚ÄúOne-Night Stands‚Äù vs ‚ÄúPower Users‚Äù vs ‚ÄúWindow Shoppers‚Äù), helping to tailor marketing or engagement strategies to each user persona.
‚è≥ Survival Analysis (Kaplan-Meier): Applies Kaplan-Meier survival curves to model user retention over time. This analysis shows what fraction of users remain active as weeks go by since signup, and allows comparison between different cohorts (e.g., users from different platforms or acquisition channels) to identify which groups retain better.
üìä Interactive Dashboard: Built with Streamlit, the dashboard front-end allows interactive filtering and exploration. Users can filter the data by signup platform or other criteria using a sidebar, and the app dynamically updates charts and metrics. It features key metrics like Total Users and Overall Churn Rate, and visualizations such as churn rate by referral source, retention curves, cohort retention heatmaps, and cluster scatterplots ‚Äì all updated in real-time based on the selected filters.
Tech Stack
Python ‚Äì Core language for data processing and machine learning.
Streamlit ‚Äì Front-end framework for the interactive dashboard UI.
MySQL ‚Äì Relational database for storing user and session data.
SQLAlchemy ‚Äì ORM (Object-Relational Mapper) for database connectivity in Python.
Scikit-learn ‚Äì Used for machine learning tasks (e.g. clustering with GMM, data preprocessing).
TensorFlow ‚Äì Used to build and train the churn prediction neural network.
LIME ‚Äì Library for model interpretability (explaining predictions of the ML model).
Lifelines ‚Äì Python library for survival analysis (used for Kaplan-Meier retention curves).
Hugging Face Transformers ‚Äì (Planned/optional) for NLP or advanced analytics (e.g. could be used to analyze text data or power a Q&A assistant on the data).
LangChain ‚Äì (Planned/optional) for integrating language models, possibly to enable conversational queries or insights on the dashboard data.
Setup Instructions
Clone the Repository: Begin by cloning the CohortIQ project repository from GitHub to your local machine. Navigate into the project directory.
Python Environment: Ensure you have Python 3.x installed. It's recommended to use a virtual environment (venv or Conda). Install the required libraries by running: pip install -r requirements.txt (if a requirements file is provided), or manually install the key packages listed in the Tech Stack (Streamlit, SQLAlchemy, MySQL connector, Scikit-learn, TensorFlow, LIME, Lifelines, etc.).
Database Setup (MySQL): Install MySQL and create a database for the project (e.g., a database named cohortiq). Import the provided SQLFILECohortiq.sql script into your MySQL instance ‚Äì this will create the necessary tables (users, sessions) and populate them with sample data. You can import via MySQL command line or a tool like MySQL Workbench.
Note: The default database connection is configured for a local MySQL instance with user root and password AniRedd@2141. If your MySQL credentials differ, update the connection string in dashboard.py (or in the app's config) accordingly (look for the line defining create_engine(mysql+mysqlconnector://...) and modify as needed).
Run the Streamlit App: In the project directory, launch the app with the command: streamlit run dashboard.py. This will start a local web server and open the CohortIQ dashboard in your browser (usually at http://localhost:8501). You should see the dashboard title and a sidebar for filters along with metrics and charts updating from the sample data.
Streamlit Cloud Deployment (Optional): CohortIQ is designed to be easily deployed on Streamlit Cloud for sharing. To deploy, you can push the code to a GitHub repository and use Streamlit‚Äôs sharing platform to host it. You may need to configure Streamlit Secrets for the database connection or modify the app to use a cloud database (since Streamlit Cloud cannot directly run a local MySQL instance). For demo purposes, you could replace the MySQL connection with a small in-memory dataset or use an online database.
Screenshots
Main CohortIQ Dashboard view, showing the interactive interface. The left sidebar provides filters (e.g., by signup platform), and the main panel displays KPI metrics at the top (Total Users, Churn Rate). In this example, there are 10 total users and a churn rate of 0% (since none have churned in the sample data). Below the KPIs, a bar chart ‚ÄúChurn by Referral Source‚Äù breaks down the churn rate by how users were referred (Ads, Invite, Organic). All charts and metrics update live based on the selected filter, giving users instant insights for the segment they're interested in. Survival Analysis: Kaplan-Meier survival curves showing user retention over time, grouped by signup platform (Web, iOS, Android). The x-axis represents time (e.g., days or weeks since signup) and the y-axis is the proportion of users still active (not churned). Each line corresponds to a platform cohort‚Äôs retention trend. In this sample, all platforms show a similar retention initially (and since the dataset is small and recent, the curves stay near 100%). This analysis helps compare how quickly users from different platforms churn ‚Äì a steeper drop would indicate faster churn for that cohort. *User Segmentation (GMM Clusters): Visualization of user segments identified via Gaussian Mixture Model clustering. Using PCA for two-dimensional plotting, each point represents a user, and points are colored by their segment. Three distinct clusters/personas emerge in this example:
‚ÄúOne-Night Stands‚Äù (blue cluster): users who sign up and only use the product once or twice (low engagement, likely to churn).
‚ÄúPower Users‚Äù (orange cluster): highly engaged users with frequent and long sessions.
‚ÄúWindow Shoppers‚Äù (green cluster): users who use the product sporadically or with moderate engagement.
This clustering helps in understanding the different types of users and tailoring retention strategies for each group.*
Cohort Retention Heatmap: A cohort analysis matrix depicting user retention by weekly signup cohorts. Each row represents users who joined in a given week, and each column represents the retention rate after a certain number of weeks since signup. The cell values (and their color intensity) show the percentage of the cohort still active in that week. For example, in the dummy data above, users who signed up the week of 2025-06-02 had about 33% still active after 1 week. This heatmap format quickly highlights retention patterns ‚Äì darker cells on the right mean stronger long-term retention. It helps identify if early-user engagement is improving or worsening over different signup cohorts. LIME Model Explanation: An example of explaining a churn prediction for an individual user using LIME. The model predicted this user will Not Churn with 94% probability (versus 6% chance to churn). The LIME explanation shows which features influenced this prediction: features like total_sessions, first_week_sessions, and avg_session_duration (blue bars) push the prediction towards ‚ÄúNot Churn‚Äù (i.e., they are evidence the user is likely to stay, since this user was quite active early on). Conversely, a feature like time_since_last_session with an orange bar (if high) might push toward ‚ÄúChurn‚Äù. These explanations make it clear why the model is predicting a user will stay or leave, increasing trust in the model's outputs.
Usage
Using the CohortIQ dashboard is intuitive:
Filtering Data: Utilize the sidebar on the left to filter users by attributes such as Signup Platform. By default, ‚ÄúAll‚Äù platforms are included. Selecting a specific platform (Web, iOS, or Android) will update the entire dashboard to show metrics and charts for that subset of users. This allows you to drill down and compare churn and engagement metrics for different user segments easily.
Key Metrics: At the top of the dashboard, two headline metrics are displayed:
Total Users: the count of users in the current filtered selection.
Churn Rate: the percentage of those users who are defined as churned. (In this project‚Äôs context, a user is considered churned if they haven‚Äôt had any activity in the last 30 days.)
These KPIs give a quick health check of the user base. For example, if you filter to ‚ÄúWeb‚Äù users, you can immediately see how many have signed up via Web and what portion have churned.
Interpreting Visualizations: The dashboard presents several charts to help interpret user behavior and churn:
Churn by Referral Source: a bar chart showing the churn rate grouped by how users were referred (e.g., Ads, Invite, Organic). This reveals which acquisition channels yield ‚Äústickier‚Äù users versus those that churn more. For instance, if the ‚ÄúOrganic‚Äù bar is taller than ‚ÄúInvite,‚Äù it implies organically acquired users have a higher churn rate.
Survival Curve: an interactive line chart (Kaplan-Meier) that plots the retention of users over time. You can hover over the lines to see the percentage of users still active after X days/weeks. Comparing curves (say between Web vs iOS users) tells you if one group retains significantly better than another over the long run.
Retention Cohort Heatmap: a matrix illustrating retention by cohort (as shown above). Each row is a cohort (group of users who joined in the same week or month), and each column is the retention at subsequent time intervals. By scanning across a row, you can see how quickly that cohort drops off. This helps identify trends ‚Äì for example, if newer cohorts (lower rows) have lighter colors earlier, retention is worsening and might need attention.
User Segments Scatterplot: an interactive scatterplot of user clusters. Hovering over or selecting points could show user details. By observing the distribution of clusters, you can identify what proportion of users fall into each segment (e.g., many in ‚ÄúOne-Night Stands‚Äù would signal a lot of one-time users). This visualization aids in targeting the largest or most at-risk segments.
Prediction Explanations: While the LIME explanations are primarily demonstrated in the development environment (Jupyter Notebook) for now, you can use them to investigate individual cases. For a given user (identified by ID or email in the dataset), you can generate a LIME explanation to understand why the model predicted them as churn/not churn. In a future iteration of the dashboard, a feature could be added to select a user and display their LIME explanation on the app itself, enabling on-the-fly interpretation of predictions.
By combining these features, CohortIQ allows you to interactively explore the data: for example, you might filter to ‚ÄúAndroid‚Äù users, notice a high churn rate, use the referral source chart to see if many came from Ads, examine the survival curve to determine when they tend to drop off, and look at the heatmap or clusters to get further context on their behavior. Each component of the dashboard works together to provide a comprehensive view of user retention dynamics.
Future Work
This project is a starting point and has several opportunities for expansion:
Scale the Database: Currently, CohortIQ uses a small MySQL sample database. The plan is to scale up to a larger dataset or connect to a cloud-based database to handle real production data. This includes optimizing queries or using a data warehouse if necessary, so the dashboard can support thousands of users and sessions with low latency.
Automate Model Retraining: The churn prediction model could be improved by automating the machine learning pipeline. As new data comes in (new users or more sessions), an automated job could retrain the neural network on the latest data and update the model. This ensures the churn predictions remain accurate over time. Additionally, model monitoring and versioning can be implemented to track performance (e.g., using tools like MLflow).
Live Deployment: Hosting the app for live use is a priority. Beyond just Streamlit Cloud, this could mean deploying on a cloud platform (AWS, GCP, or Heroku) along with a managed database. A live deployment would allow stakeholders or recruiters to play with the dashboard in real-time. It also involves setting up proper authentication, so that sensitive data is protected if using real user information.
Enhanced Features: There are several feature enhancements under consideration. For example, integrating a conversational analytics assistant using an LLM (via LangChain and Hugging Face Transformers) could allow users to ask questions about the data in natural language (e.g., "Which cohort has the highest 8-week retention?") and get answers or generated charts. Other ideas include adding more filters (such as date ranges or user segments), implementing alerting (notifications when churn rate exceeds a threshold), and improving the UI/UX with custom components.
By iterating on these improvements, CohortIQ can evolve from a portfolio demo into a robust, scalable application for real-world churn analysis and retention strategy.
Author
Anirudh ‚Äì Creator and developer of CohortIQ. This project was implemented as part of a data science portfolio to demonstrate skills in data engineering, machine learning, and interactive dashboard development. Feel free to reach out via GitHub or LinkedIn for any questions or collaboration opportunities!